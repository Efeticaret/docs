Amazon S3
===

```{toctree}
:hidden:

Alibaba
Cynny
DigitalOcean
DreamObjects
Dunkel
EMC
Eucalyptus
Exoscale
Filebase
IAM
IBM_COS
IDrive_Cloud
MinIO
Oracle_Cloud
Pilvio
Polycloud
Scaleway
Scality
Spectra
Verizon
Wasabi
Z1
```

```{image} _images/s3.png
:alt: Send Command
:width: 128px
```

Transfer files to your [S3](http://aws.amazon.com/s3) account and browse the S3 buckets and files in a hierarchical way. For a short overview of Amazon S3, refer to the [Wikipedia article](http://en.wikipedia.org/wiki/Amazon_S3).

# Connecting

You must obtain the login credentials (Access Key ID and Secret Access Key) of your [Amazon Web Services Account](http://aws.amazon.com/account/) from the [*AWS Access Identifiers page*](https://console.aws.amazon.com/iam/home?#security_credential). Enter the *Access Key ID* and *Secret Access Key* in the login prompt.

## IAM User

You can also connect using [IAM](IAM) credentials that have the `Amazon S3 Full Access` template policy permissions attached and optionally the `CloudFront Full Access`. Make sure you are connecting with `AWS4-HMAC-SHA256` signature version (see above).

## Generic S3 Profiles

For use with third party S3 installations.

`````{tabs}

````{tab} AWS4

**Authentication with signature version AWS4-HMAC-SHA256**

**HTTP**</br>
```{Important}
It is discouraged to enable this option to connect plaintext to Amazon S3.
```

If you have an S3 installation without SSL configured, you need an optional connection profile to connect using HTTP only without transport layer security. You will then have the added option S3 (HTTP) in the protocol dropdown selection in the [Connection](../../Cyberduck/Connection) and [Bookmark](../../Cyberduck/Bookmarks) panels.

* {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20(HTTP).cyberduckprofile>` the *S3 (HTTP) profile* for preconfigured settings.

**HTTPS**</br>
- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20(HTTPS).cyberduckprofile>` the *S3 (HTTPS) profile* for preconfigured settings.
````

````{tab} AWS2

**Authentication with signature version AWS2**

An incomplete list of known providers that require the use of AWS2
- Riak Cloud Storage
- [EMC Elastic Cloud Storage](EMC)

**HTTP**</br>
- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20AWS2%20Signature%20Version%20(HTTP).cyberduckprofile>` the S3 AWS2 Signature Version (HTTP) profile for preconfigured settings.

**HTTPS**</br>
- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20AWS2%20Signature%20Version%20(HTTPS).cyberduckprofile>` the S3 AWS2 Signature Version (HTTPS) profile for preconfigured settings.
````

`````

## AWS Gov Cloud

### S3 GovCloud (US-East)

Use the endpoint `s3-us-gov-east-1.amazonaws.com` or install the connection profile

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20GovCloud%20(US-East).cyberduckprofile>` the *S3 GovCloud (US-East) profile* for preconfigured settings.

### S3 GovCloud (Us-West)

Use the endpoint `s3-us-gov-west-1.amazonaws.com` or install the connection profile

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20GovCloud%20(US-East).cyberduckprofile>` the *S3 GovCloud (US-West) profile* for preconfigured settings.

## AWS China (Beijiing)

Connect to the region *AWS China (Beijing)*

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20China%20(Beijing).cyberduckprofile>` the *S3 China (Beijing) profile* for preconfigured settings.

## AWS Private Link

Connect to [S3 interface VPC endpoint](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/AWS%20PrivateLink%20for%20Amazon%20S3%20(VPC%20endpoint).cyberduckprofile>` the *AWS PrivateLink for Amazon S3 (VPC endpoint) profile*.

## Access Third Party Buckets

Connecting to a bucket you are not the owner (and therefore not included when logging in as above and listing all your owned buckets) is possible. You can access buckets owned by someone else if the ACL allows you to access it by either:

1. Specify the bucket you want to access in the hostname to connect to like `<bucketname>.s3.amazonaws.com`. Your own buckets will not be displayed but only the third-party bucket.
2. Set the *Default Path* in the bookmark to the bucket name.
3. Choose *Go → Go to Folder…* when already connected.

## Connecting with Temporary Access Credentials (Token) from EC2

If you are running Cyberduck for Windows or [Cyberduck CLI](https://duck.sh/) on EC2 and have setup [IAM Roles for Amazon EC2](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html) to provide access to S3 from the EC2 instance, you can use the connection profile below that will fetch temporary credentials from EC2 instance metadata service at `http://169.254.169.254/latest/meta-data/iam/security-credentials/s3access` to authenticate. Edit the profile to change the role name `s3access` to match your IAM configuration.

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20(Credentials%20from%20Instance%20Metadata).cyberduckprofile>` the *S3 (Credentials from Instance Metadata) profile* for preconfigured settings

## Connecting Using Credentials in `~/.aws/credentials`

Instead of providing Access Key ID and Secret Access Key, authenticate using credentials managed in `~/aws/credentials` using third-party tools.

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20(Credentials%20from%20AWS%20Command%20Line%20Interface).cyberduckprofile>` the *S3 (Credentials from AWS Command Line Interface) profile* for preconfigured settings. 

You must provide configuration in the standard credentials property file `~/.aws/credentials` from [AWS Command Line Interface](https://docs.aws.amazon.com/cli/latest/userguide/cli-multiple-profiles.html). Configure a bookmark with the field titled *Profile Name in ~/.aws/credentials* matching the profile name from `~/.aws/credentials`. The properties `aws_access_key_id`, `aws_secret_access_key` and `aws_session_token` are supported.

You might be interested in scripts maintained by third parties to facilitate managing credentials

- [Manage configuration files for Cyberduck S3 (AssumeRoles from AWS STS)](https://github.com/jmvbxx/cyberduck-s3-config)
- [Utilities for easy management of AWS MFA and role sessions and virtual MFA devices](https://github.com/vwal/awscli-mfa)

## Connecting Using AssumeRole from AWS Security Token Service (STS)

Instead of providing Access Key ID and Secret Access Key, authenticate using temporary credentials from AWS Security Token Service (STS) with optional Multi-Factor Authentication (MFA). Refer to U[sing IAM Roles](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use.html).

![MFA Token Prompt](_images/MFA_Token_Prompt.png)

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20(Credentials%20from%20AWS%20Security%20Token%20Service).cyberduckprofile>` the *S3 (Credentials from AWS Security Token Service) profile* for preconfigured settings.

You must provide configuration in the standard credentials property file `~/.aws/credentials` from [AWS Command Line Interface](https://docs.aws.amazon.com/cli/latest/userguide/cli-multiple-profiles.html). Configure a bookmark with the field titled *Profile Name* in `~/.aws/credentials` matching the profile name from `~/.aws/credentials` with the `role_arn` configuration.

### Example configuration

Refer to [Assuming a Role](https://docs.aws.amazon.com/cli/latest/userguide/cli-roles.html).

	[testuser]
	aws_access_key_id=<access key for testuser>
	aws_secret_access_key=<secret key for testuser>
	[testrole]
	role_arn=arn:aws:iam::123456789012:role/testrole
	source_profile=testuser
	mfa_serial=arn:aws:iam::123456789012:mfa/testuser

## Read Credentials from `~/.aws/credentials`

When editing a bookmark, the *Access Key ID* is set from the `default` profile in the credentials file located at `~/.aws/credentials` if such a profile exists.

# Cyberduck CLI

List all buckets with [Cyberduck CLI](https://duck.sh/) using

	duck --username <Access Key ID> --list s3:/

List the contents of a bucket with

	duck --username <Access Key ID>  --list s3:/<bucketname>/

Refer to the [Cyberduck CLI documentation](../../CLI/index) for more operations.

# Third Party Providers

There are a growing number of third parties besides Amazon offering S3 compatible cloud storage software or solutions. Here is a non-exhaustive list:

- [Aruba Cloud](https://www.cloud.it/)
- [Connectria Cloud Storage](https://www.mh.connectria.com/rp/order/cloud_storage_index)
- [DreamObjects Cloud Storage](DreamObjects)
- [Dunkel Cloud Storage](Dunkel)
- [Eucalyptus Walrus](Eucalyptus)
- [Google Storage](../Google_Cloud_Storage)
- [Outscale (using CEPH Opensource)](https://www.outscale.com/)
- [Scaleway](https://www.scaleway.com/docs/store-object-with-cyberduck/)
- [Scality (proprietary technology)](Scality)
- [Seeweb](https://www.seeweb.it/)
- [Exoscale Swiss Object Storage](Exoscale)
- [Verizon Cloud Storage](Verizon)
- [Spectra BlackPearl Deep Storage Gateway](Spectra)
- [MinIO Cloud Storage](MinIO)
- [Cynny Space](Cynny)
- [Cloudian HyperStore Appliance](https://cloudian.com/products/hyperstore/)
- [Swisscom S3 Dynamic Storage](https://www.swisscom.ch/en/business/enterprise/offer/cloud-data-center/dynamic-computing-services.html)
- [NetApp StorageGrid Webscale](https://docs.netapp.com/sgws-114/index.jsp)
- [Wasabi Storage](Wasabi)
- [DigitalOcean Spaces](DigitalOcean)
- [IBM Cloud Object Storage (COS)](IBM_COS)
- [Oracle Storage Cloud Service](Oracle_Cloud#OCIObjectStorage)
- [Alibaba Cloud Object Storage Service (OSS)](Alibaba)
- [Vultr Object Storage](https://www.vultr.com/docs/vultr-object-storage#Cyberduck_GUI_tool)
- [Linode Object Storage](https://www.linode.com/docs/platform/object-storage/how-to-use-object-storage/#cyberduck)
- [Filebase](Filebase)
- [Z1 Storage](Z1)
- [Pilvio](Pilvio)
- [IDrive® Cloud](IDrive_Cloud#s3)
- [EMC Elastic Cloud Storage](EMC)
- [Polycloud](Polycloud)
- [Scaleway Object Storage](Scaleway)

# File System

## Buckets

### Creating a Bucket

o create a new [bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket-s3.html) for your account, browse to the root and choose *File → New Folder... (macOS `⌘N` Windows `Ctrl+Shift+N`)*. You can choose the bucket location in *Preferences (macOS `⌘,` Windows `Ctrl+,`) → S3*. Note that Amazon has a different pricing scheme for different regions.

```{attention}
Mountain Duck 4.6.1 or later: You will receive a prompt for the region when creating a new bucket
```

**Supported Regions**
- EU (Ireland)
- EU (London)
- EU (Paris)
- EU (Stockholm)
- US East (Northern Virginia)
- US West (Northern California)
- US West (Oregon)
- Asia Pacific (Singapore)
- Asia Pacific (Tokyo)
- South America (São Paulo)
- Asia Pacific (Sydney)
- EU (Frankfurt)
- US East (Ohio)
- Asia Pacific (Seoul)
- Asia Pacific (Mumbai)
- Canada (Montreal)
- China (Beijing)
- China (Ningxia)

![Create Bucket](_images/Create_Bucket.png)

```{important}
- Because the bucket name must be globally unique the operation might fail if the name is already taken by someone else (E.g. don't assume any common name like *media* or *images* will be available).
- You cannot change the location of an existing bucket.
```

### Bucket Access Logging

When this option is enabled in the S3 panel of the Info (*File → Info (macOS `⌘I` Windows `Alt+Return`)*) window for a bucket or any file within, available log records for this bucket are periodically aggregated into log files and delivered to `/logs` in the target logging bucket specified. It is considered best practice to [choose a logging target](http://blog.qloudstat.com/2012/04/24/choose-a-logging-target/) that is different from the origin bucket.

![AWS Logging Configuration](_images/AWS_Logging_Configuration.png)

To toggle CloudFront access logging, select the the [Distribution](../../CDN/CloudFront) panel in the File → Info (macOS `⌘I` Windows `Alt+Return`) window.

## Versions

[Versioning](http://aws.amazon.com/s3/faqs/#What_is_Versioning) can be enabled per bucket in *File → Info (macOS `⌘I` Windows `Alt+Return`) → S3*. Make sure the user has `s3:PutBucketVersioning` permission permits users to modify the versioning configuration of a bucket.

You can view all revisions of a file in the browser by choosing *View → Show Hidden Files*.

### Revert

To revert to a previous version and make it the current, choose *File → Revert*.

### Multi-Factor Authentication (MFA) Delete

To enable *Multi-Factor Authentication (MFA) Delete*, you need to purchase a compatible [authentication device](http://aws.amazon.com/mfa/). Toggle MFA in *File → Info (macOS `⌘I` Windows `Alt+Return`) → S3*. When enabled, you are prompted for the device number and one-time token in the login prompt. Never reenter a token in the prompt already used before. A token is only valid for a single request. Wait for the previous token to disappear from the device screen and request a new token from the device.

![MFA Credentials](_images/MFA_Credentials.png)

### References

- [Using versioning in S3 buckets](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html#MultiFactorAuthenticationDelete)

## Folders

Creating a folder inside a bucket will create a placeholder object named after the directory, has no data content, and the MIME type `application/x-directory`.

### Supported Third Party Folder Placeholder Formats

- Folders created with [AWS Management Console](http://aws.amazon.com/console/).

## File Transfers

### Transfer Acceleration

When enabled for the bucket, downloads, and uploads using the S3 Transfer Acceleration endpoints to transfer data through CloudFront’s globally distributed edge locations. The name of the bucket used for Transfer Acceleration must be DNS-compliant and must not contain periods ("."). You do **not** need to enter transfer accelerated endpoints manually. When using Transfer Acceleration, additional data transfer charges may apply to connect to `s3-accelerate.dualstack.amazonaws.com`.

![Transfer Acceleration](_images/Amazon_S3_Transfer_Acceleration.png)

#### Permissions

Make sure the user has `s3:GetAccelerateConfiguration` permission permits users to return the Transfer Acceleration state of a bucket.

### Checksums

Files are verified both by AWS when the file is received and compared with the `SHA256` checksum sent with the request. Additionally, the checksum returned by AWS for the uploaded file is compared with the checksum computed locally if enabled in *Transfers → Checksum → Uploads → Verify checksum*.

### Multipart Uploads

Files larger than 100MB are uploaded in parts with up to 10 parallel connections as 10MB parts. Given these sizes, the file size limit is 100GB with a maximum of 10'000 parts allowed by S3. The number of connections used can be limited using the toggle in the lower right of the transfer window.

Multipart uploads can be resumed later when interrupted. Make sure the user has the permission `s3:ListBucketMultipartUploads`.

#### Unfinished multipart uploads

You can view unfinished multipart uploads in the browser by choosing *View → Show Hidden Files*.

#### Options

You can set options with the following [hidden configuration options](../../Cyberduck/Preferences#hidden-configuration-options).

Part size for multipart uploads

	s3.upload.multipart.size=10485760

Threshold to use multipart uploads is set to 100MB by default

	s3.upload.multipart.threshold=104857600

# Storage Class

You have the option to store files using the *Reduced Redundancy Storage (RRS)* by storing non-critical, reproducible data at lower levels of redundancy. Set the default storage class in *Preferences (macOS `⌘,` Windows `Ctrl+,`) → S3* and [edit the storage class](../../Cyberduck/Info#amazon-s3-panel) for already uploaded files using *File → Info (macOS `⌘I` Windows `Alt+Return`) → S3*. Available storage classes are

- Regular Amazon S3 Storage
- Intelligent-Tiering
- Standard IA (Infrequent Access)
- One Zone-Infrequent Access
- Reduced Redundancy Storage (RRS)
- Glacier
- Glacier Deep Archive

## Lifecycle Configuration

Specify after how many days a file in a bucket should be moved to Amazon Glacier or deleted.

![Lifecycle Configuration](_images/Lifecycle-Configuration-for-S3-Windows.png)

## Restore from Glacier

```{attention}
This function is Cyberduck only.
```

You can temporarily restore files from Glacier using *File → Restore*. The file will be restored using standard retrieval and expire 2 days after retrieval. Restoring takes some time and attempting to download an item not yet restored will lead to an error T*he operation is not valid for the object's storage class*.

### Glacier Retrieval Options

You can set retrieval options with the following [hidden configuration options](../../Cyberduck/Preferences#hidden-configuration-options).

Sets Glacier retrieval tier at which the restore will be processed.

	s3.glacier.restore.tier=Standard

→ Valid values are `Standard`, `Bulk`, `Expedited`.

Sets the time, in days, between when an object is uploaded to the bucket and when it expires.

	s3.glacier.restore.expiration.days=2

# Access Control (ACL)

Amazon S3 uses Access Control List (ACL) settings to control who may access or modify items stored in S3. You can edit ACLs in *File → Info (macOS `⌘I` Windows `Alt+Return`) → Permissions*.

![ACLs](_images/ACLs.png)

## Canonical User ID Grantee

If you enter a user ID unknown to AWS, the error message `S3 Error Message. Bad Request. Invalid id.` will be displayed.

## Email Address Grantee

If you enter an email address unknown to AWS, the error message `S3 Error Message. Bad Request. Invalid id.` will be displayed. If multiple accounts are registered with AWS for the given email address, the error message `Bad Request. The e-mail address you provided is associated with more than one account. Please retry your request using a different identification method or after resolving the ambiguity.` is returned.

## All Users Group Grantee

You must give the group grantee `http://acs.amazonaws.com/groups/global/AllUsers` read permissions for your objects to make them accessible using a regular web browser for everyone.

If [bucket logging](index#bucket-access-logging) is enabled, the bucket ACL will have `READ_ACP` and `WRITE` permissions for the group grantee `http://acs.amazonaws.com/groups/s3/LogDelivery`.

## Default ACLs

You can set a [default ACL](https://docs.aws.amazon.com/AmazonS3/latest/userguide/acl-overview.html#canned-acl) set on new files uploaded and buckets created in *Preferences (macOS `⌘,` Windows `Ctrl+,`) → S3 → Default ACL*.

|  | Applies to buckets | Applies to files |
| --- | :---: | :---: |
| `private` | ✅ | ✅ |
| `public-read` | ✅ | ✅ |
| `public-read-write` | ✅ | ✅ |
| `authenticated-read` | ✅ | ✅ |
| `bucket-owner-read` | ❌	| ✅ |
| `bucket-owner-full-control` | ❌	| ✅ |

## Permissions

The following permissions can be given to grantees:

|  | Bucket | Files |
| --- | --- | --- |
| `READ` | Allows grantee to list the files in the bucket | Allows grantee to download the file and its metadata |
| `WRITE` | Allows grantee to create, overwrite, and delete any file in the bucket | Not applicable |
| `FULL_CONTROL` | Allows grantee all permissions on the bucket | Allows grantee all permissions on the object |
| `READ_ACP` | Allows grantee to read the bucket ACL | Allows grantee to read the file ACL |
| `WRITE_ACP` | Allows grantee to write the ACL for the applicable bucket | Allows grantee to write the ACL for the applicable file |

# Public URLs

You can access all URLs (including from [CDN](../../CDN/CloudFront) configurations) from the menu *Edit → Copy URL and File → Open URL*.

![Copy URLs](_images/Copy_URLs.png)

## Pre-signed Temporary URLs

A private object stored in S3 can be made publicly available for a limited time using a pre-signed URL. The pre-signed URL can be used by anyone to download the object, yet it includes a date and time after which the URL will no longer work. Copy the pre-signed URL from *Edit → Copy URL→ Signed URL* or *File → Info (macOS `⌘I` Windows `Alt+Return`) → S3*.

There are pre-signed URLs that expire in one hour, 24 hours (using the preference `s3.url.expire.seconds`), a week, and a month. You can change the [hidden preference](../../Cyberduck/Preferences#hidden-configuration-options) `s3.url.expire.seconds` from the default `86400` (24 hours).

```{important}
It is required that your AWS credentials are saved in keychain. Refer to [Passwords](../../Cyberduck/Connection#Passwords).
```

### Force use of AWS2 Signature

Using the AWS4 signature version used in Cyberduck version 5.0 and later, pre-signed URLs cannot have an expiry date later than a week. You can revert by setting the default signature version to AWS2 by using the *S3 AWS2 Signature Version (HTTP) connection profile*.

```{note}
This deprecated signature version is not compatible with new regions such as `eu-central-1`.
```

## BitTorrent URLs

Use *File → Info (macOS `⌘I` Window `Alt+Return`) → S3* to copy the BitTorrent URL of a selected file. The ACL of the object must allow anonymous read. One important thing to note is that the `.torrent` file describing an Amazon S3 object is generated on-demand, the first time the Torrent URL is requested. Generating the `.torrent` for an object takes time proportional to the size of that object. For large objects, this time can be significant. Therefore, before publishing a `?torrent` link, we suggest making the first request for it yourself. Amazon S3 might take several minutes to respond to this first request, as it generates the `.torrent` file. Unless you update the object in question, subsequent requests for the `.torrent` will be fast.

# Metadata

You can edit standard HTTP headers and add [custom HTTP headers](../../Cyberduck/Info#metadata-http-headers) to files to store [metadata](http://docs.amazonwebservices.com/AmazonS3/latest/index.html?UsingMetadata.html). Choose *File → Info (macOS `⌘I` Windows `Alt+Return`) → Metadata* to edit headers.

## Default Metadata

Currently only possible using a [hidden configuration option](../../Cyberduck/Preferences#hidden-configuration-options) you can define default headers to be added for uploads. Multiple headers must be separated using a whitespace delimiter. Key and value of a header are separated with `=`. For example, if you want to add an HTTP header for Cache-Control and one named `Creator` you would set

	s3.metadata.default="Cache-Control=public,max-age=86400 Creator=Cyberduck"

## Cache Control Setting

This option lets you control how long a client accessing objects from your S3 bucket will cache the content and thus lowering the number of access to your S3 storage. In conjunction with Amazon CloudFront, it controls the time an object stays in an edge location until it expires. After the object expires, CloudFront must go back to the origin server the next time that edge location needs to serve that object. By default, all objects automatically expire after 24 hours when no custom `Cache-Control` header is set.

The default setting is `Cache-Control: public,max-age=2052000` when choosing to add a custom `Cache-Control` header in the [Info](../../Cyberduck/Info) panel which translates to a cache expiration of one month (one month in seconds equals more or less `60*60*24*30`).

Use the [hidden configuration option](../../Cyberduck/Preferences#hidden-configuration-options) `s3.cache.seconds` to set a custom default value

	s3.cache.seconds=2052000

## References

- [Amazon CloudFront and Your Live System](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.html)
- Read more about [Amazon CloudFront Object Expiration](http://docs.amazonwebservices.com/AmazonCloudFront/latest/DeveloperGuide/index.html?Expiration.html)

```{tip}
Use `curl -I <http://<bucketname>.s3.amazonaws.com/<key>` to debug HTTP headers.
```

# Server Side Encryption (SSE)

[Server-side encryption](http://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html) for stored files is supported and can be enabled by default for all uploads in the S3 preferences or for individual files in the *File → Info (macOS `⌘I` WIndows `Alt+Return`) → S3*. AWS handles key management and key protection for you.

## Defaults

Choose *Preferences → S3 → Server Side Encryption* to change the default.

- *None* will not encrypt files (Default).
- *SSE-S3* will encrypt files using *AES-256* with a default key provided by S3.
- *SSE-KMS* will encrypt files with the default key stored in AWS Key Management Service (KMS).

You can override these default settings in the *File → Info (macOS `⌘I` Windows `Alt+Return`) → S3* panel per bucket.

## Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)

When changing the setting for a folder or bucket you are prompted to confirm the recursive operation on all files contained in the selected bucket or folder.

## Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)

Among the default `SSE-S3 (AES-256)`, the server-side encryption (SSE) dropdown list allows choosing from all private keys managed in AWS Key Management Service (KMS).

### Permissions

This requires the `kms:ListKeys` and `kms:ListAliases` permission for the AWS credentials used to connect to S3.

![AWS SSE-KMS Private Key Selection](_images/AWS_SSE-KMS_Private_Key_Selection.png)

When changing the setting for a folder or bucket you are prompted to confirm the recursive operation on all files contained in the selected bucket or folder.

## Prevent Uploads of Unencrypted Files

Refer to the AWS Security Blog

- [How to Prevent Uploads of Unencrypted Objects to Amazon S3](https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/)

# CloudFront CDN

Amazon CloudFront delivers your static and streaming content using a global network of edge locations. Requests for your objects are automatically routed to the nearest edge location, so content is delivered with the best possible performance. Refer to [Amazon CloudFront distribution](../../CDN/CloudFront) for help about setting up distributions.

# Website Configuration

To host a static website on S3, It is possible to define an Amazon S3 bucket as a *Website Endpoint*. The configuration in *File → Info (macOS `⌘I` Windows `Alt+Return`) → Distribution* allows you to enable website configuration. Choose *Website Configuration (HTTP)* from *Delivery Method* and define an index document name that is searched for and returned when requests are made to the root or the subfolder of your website.

To access this website functionality, Amazon S3 exposes a new website endpoint for each region (US Standard, US West, EU, or Asia Pacific). For example, `s3-website-ap-southeast-1.amazonaws.com` is the endpoint for the Asia Pacific Region. The location is displayed in the *Where* field following the *Origin*.

![S3 Website Configuration](_images/S3_Website_Configuration.png)

To configure Amazon CloudFront for your website endpoints, refer to [Website Configuration Endpoint Distributions with CloudFront CDN](../../CDN/CloudFront#website-configuration-endpoint-distributions-with-cloudfront-cdn).

## References

- [Host Your Static Website on Amazon S3](http://aws.typepad.com/aws/2011/02/host-your-static-website-on-amazon-s3.html)
- [Amazon S3 adds new features for hosting static websites](http://aws.amazon.com/about-aws/whats-new/2011/02/17/Amazon-S3-Website-Features/)

# Known Issues

## Disable use of Virtual Host Style Requests

Set the [hidden preference](../../Cyberduck/Preferences#hidden-configuration-options) `s3.bucket.virtualhost.disable` to `true` if your S3 compatible storage does only support path style requests to reference buckets. Alternatively a custom connection [profile](../../Cyberduck/Profiles) with the property set in `Properties`.

- {download}`Download<https://svn.cyberduck.io/trunk/profiles/S3%20(Deprecated%20path%20style%20requests).cyberduckprofile>` the *S3 (Deprecated path style requests) profile* for preconfigured settings.

## Moved Permanently but no Location Header

Make sure the IAM user has the permission `s3:GetBucketLocation` to read the bucket location.

## Writing Files to S3 Compatible Third Party Service Provider may Fail

The S3 interoperable service must support [multipart uploads](http://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html).

## Delete Marker

When overwriting files some applications (like Windows File Explorer) will delete files prior to writing the new file. Thus we also forward this delete operation to S3 resulting in the delete marker being set. You can overwrite files with command-line tools which typically do not delete files prior to overwriting.

## In Finder.app, Creating a new Top-Level Folder in S3 Fails with `Interoperability failure. Bucket name is not DNS compatible. Please contact your web hosting service provider for assistance.`

A bucket name in S3 cannot have whitespace in the filename. Because a new folder created with Finder.app is named `Untitled Folder` the operation fails. As a workaround, create a new bucket with `mkdir` in *Terminal.app*.

```{note}
The bucket can be created within the Smart Synchronization mode as the folder only gets uploaded after it is renamed. Make sure to choose a filename with no whitespace. For the additional restrictions of the bucket name, refer to the [AWS bucket naming rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html).
```


## Saving a file in TextEdit.app will Attempt to Create a Folder `/Temporary Items` on the Remote Volume. On some Servers, this may fail due to a Permission Failure or Because the Name of the Folder is not Allowed as in S3.

<del>You will get the error message `Bucket name is not DNS compatible. Please contact your web hosting service provider for assistance.`.</del> As of Mountain Duck version 2.1, `.DS_Store` files are only saved in a temporary location and not stored on the mounted remote volume.

# References

- [Grant access to user-specific folders in an Amazon S3 bucket](http://blogs.aws.amazon.com/security/post/Tx1P2T3LFXXCNB5/Writing-IAM-policies-Grant-access-to-user-specific-folders-in-an-Amazon-S3-bucke)
- [Amazon Simple Storage Service FAQs](http://aws.amazon.com/s3/faqs/)
- [Amazon Simple Storage Service Developer Guide](https://docs.aws.amazon.com/AmazonS3/latest/userguide/developing-s3.html)